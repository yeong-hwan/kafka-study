# kafka-study

## Kafka: Data-Pipeline

### 1. 높은 처리량

동일한 양의 데이터를 보낼 때, 네트워크 통신 횟수를 최소한으로 줄이면 동일 시간 내에 더 많은 데이터 전송 가능

- 카프카는 많은 양의 데이터를 배치 처리하여, 빠르게 대용량 실시간 로그 데이터 처리에 적합
- 파티션 단위를 통해 동일 목적 데이터를 여러 파티션에 분배하고 병렬처리할 수 있다
- 파티션 개수만큼 컨슈머 개수를 늘려서 동일 시간당 처리량을 늘린다

### 2. 확장성

데이터가 얼마나 들어올지 예측하기 어렵다

- 카프카는 가변적인 환경에서 안정적으로 확장 가능
- 데이터가 많아지면 클러스터의 브로커 개수를 스케일 아웃할 수 있다
- 반대로 데이터가 적어지면 브로커 개수를 스케일 인 할 수 있다

### 3. 영속성

프로그램이 종료되어도 데이터는 남아있다

- 메모리가 아닌 파일시스템에 저장
- 운영체제에서 파일 I/O 성능 향상을 위해 `Page Cache` 영역을 메모리에 따로 생성하여 사용
- Page Cache 메모리 영역을 사용하여, 카프카가 한 번 읽은 파일 내용은 메모리에 저장시켰다가 다시 사용
- 어플리케이션 장애로 급작스럽게 종료되더라도 프로세스를 재시작하여 안전하게 데이터 다시 처리

### 4. 고가용성

카프카 클러스터는 3개 이상의 서버(브로커)들로 운영됨

- 여러 브로커는 데이터 replication 되어 있다.
- 1 대의 브로커에 장애가 발생해도 다른 브로커에서 데이터 처리 가능
- on-premise 서버 랙, public-cloud Region 단위 장애에 대비한 브로커 옵션 존재

<p align="center">
  <img src="./imgs/kafka-structure-1.jpeg" width="100%">
  <img src="./imgs/kafka-structure-2.jpeg" width="100%">
</p>